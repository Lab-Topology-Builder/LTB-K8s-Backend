{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Lab Topology Builder Documentation","text":"<p>The Lab Topology Builder (LTB) is an open source project that allows users to deploy networking labs on Kubernetes. It is a tool that enables you to build a topology of virtual machines and containers, which are connected to each other according to the network topology you have defined.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Deployment of networking labs on Kubernetes</li> <li>Deletion of networking labs on Kubernetes</li> <li>Status querying of lab deployments</li> </ul> <p>Upcoming features:</p> <ul> <li>Remote access to OOB management of lab nodes</li> <li>Secure remote access to OOB management of lab nodes (Access Control)</li> <li>User management</li> </ul>"},{"location":"concepts/","title":"Concepts","text":""},{"location":"concepts/#kubernetes-cluster","title":"Kubernetes Cluster","text":"<p>Kubernetes Cluster is a set of nodes that run containerized applications managed by Kubernetes.</p>"},{"location":"concepts/#lab-topology-builder-ltb","title":"Lab Topology Builder (LTB)","text":"<p>The Lab Topology Builder (LTB) is a tool that allows you to build a topology of virtual machines and containers, which are connected to each other according to the network topology you have defined.</p>"},{"location":"concepts/#ltb-kubernetes-operator","title":"LTB Kubernetes Operator","text":"<p>The LTB Kubernetes Operator  custom Kubernetes controller that allows you to deploy and manage applications and their components on Kubernetes using custom resources.</p>"},{"location":"concepts/#kubernetes-operator","title":"Kubernetes operator","text":"<p>A Kubernetes operator is an application-specific controller that extends the functionality of the Kubernetes API to create, configure, and manage instances of complex applications on behalf of a Kubernetes user. It builds upon the basic Kubernetes resource and controller concepts but includes domain or application-specific knowledge to automate the entire life cycle of the software it manages.</p>"},{"location":"concepts/#custom-resource-cr","title":"Custom Resource (CR)","text":"<p>A custom resource (CR) is an extension of the Kubernetes API that allows you to define and manage your own API objects. It provides a way to store and retrieve structured data and can be used with a custom controller to provide a declarative API. Custom resources can be defined as a Kubernetes API extension using Custom Resource Definitions (CRDs) or via API aggregation.</p>"},{"location":"concepts/#custom-resource-definition-crd","title":"Custom Resource Definition (CRD)","text":"<p>A custom resource definition (CRD) is a Kubernetes native resource. Defining a CRD object creates a new custom resource with a name and schema that you specify. The custom resource created from a CRD object can be either namespaced or cluster-scoped. CustomResourceDefinitions themselves are non-namespaced and are available to all namespaces.</p>"},{"location":"concepts/#lab-template","title":"Lab Template","text":"<p>Lab Template is a YAML file that defines the topology of the lab. It contains information about the devices that are part of the lab, as well as the network topology.</p>"},{"location":"concepts/#node","title":"Node","text":"<p>In a network, a node represents any device that is connected. Within LTB, a node can be either a KubeVirt virtual machine or a container. Each node is characterized by its type, version, and name.</p>"},{"location":"concepts/#network-topology","title":"Network Topology","text":"<p>The arrangement or pattern in which all nodes on a network are connected together is referred to as the network\u2019s topology.</p>"},{"location":"concepts/#lab","title":"Lab","text":"<p>A lab defines a set of nodes that are connected together according to a network topology.</p>"},{"location":"concepts/#lab-instance","title":"Lab Instance","text":"<p>A lab instance is a custom resource and describes a lab that is deployed in a Kubernetes cluster. It defines the name, which lab template to use and also has a status field that is updated by the operator.</p>"},{"location":"user-guide/","title":"User Guide","text":""},{"location":"user-guide/#example-lab-template","title":"Example Lab Template","text":"<p>This is an example of lab template, which you can use as a starting point for your own labs.</p> <pre><code>apiVersion: ltb-backend.ltb/v1alpha1\nkind: LabTemplate\nmetadata:\nname: labtemplate-sample\nspec:\nnodes:\n- name: \"sample-node-1\"\nimage:\ntype: \"ubuntu\"\nversion: \"22.04\"\nkind: \"vm\"\nconfig: |-\n#cloud-config\npassword: ubuntu\nchpasswd: { expire: False }\nssh_authorized_keys:\n- &lt;your-ssh-pub-key&gt;\npackages:\n- qemu-guest-agent\nruncmd:\n- [ systemctl, start, qemu-guest-agent ]\n- name: \"sample-node-2\"\nimage:\ntype: \"ghcr.io/insrapperswil/network-ninja\"\nversion: \"latest\"\n- name: \"sample-node-3\"\nimage:\ntype: \"ubuntu\"\nversion: \"latest\"\nkind: \"pod\"\nconnections:\n- neighbors: \"TestHost1:1,TestHost2:1\"\n</code></pre> <p>The above lab template will define three nodes and one connection between two of the nodes.</p>"},{"location":"user-guide/#example-lab-instance","title":"Example Lab Instance","text":"<p>This is an example of lab instance, which you can use as a starting point for your own labs.</p> <pre><code>apiVersion: ltb-backend.ltb/v1alpha1\nkind: LabInstance\nmetadata:\nname: labinstance-sample\nspec:\nlabTemplateReference: \"labtemplate-sample\"\n</code></pre> <p>The above lab instance will create a lab instance called labinstance-sample using the data from the referenced resource labtemplate-sample, which is provided at the beginning as an example.</p>"},{"location":"architecture/k8s-ltb-architecture/","title":"Kubernetes Lab Topology Builder Architecture","text":"<p>The Kubernetes Lab Topology Builder (K8s-LTB) is a Kubernetes native version of the Lab Topology Builder (LTB). It is composed of a Frontend and a Backend.</p> <p></p>"},{"location":"architecture/k8s-ltb-architecture/#frontend","title":"Frontend","text":"<p>The frontend is responsible for the following tasks:</p> <ul> <li>Providing a web UI for the user to interact with the labs.</li> <li>Providing a web UI for the admin to manage:</li> <li>users</li> <li>lab templates</li> <li>lab deployments</li> <li>reservations</li> </ul>"},{"location":"architecture/k8s-ltb-architecture/#backend","title":"Backend","text":"<p>The backend is composed of the following components:</p> <ul> <li>API</li> <li>Operator</li> </ul> <p>The backend is responsible for the following tasks:</p> <ul> <li>parsing the yaml topology files</li> <li>deploying/destroying the containers and vms</li> <li>exposes status of lab deployments</li> <li>exposes information on how to access the deployed containers and vms</li> <li>provides remote ssh capabilities</li> <li>provides remote Wireshark capture capabilities</li> <li>managing reservations (create, delete, etc.)</li> <li>exposes node resource usage</li> <li>user management</li> <li>exposes information about a device (version, groups, etc.)</li> </ul>"},{"location":"architecture/k8s-ltb-architecture/#c4-model","title":"C4 Model","text":""},{"location":"architecture/k8s-ltb-architecture/#system-context-diagram","title":"System Context Diagram","text":""},{"location":"architecture/k8s-ltb-architecture/#container-diagram","title":"Container Diagram","text":""},{"location":"architecture/k8s-ltb-architecture/#component-diagram","title":"Component Diagram","text":""},{"location":"architecture/kvm-docker-ltb-architecture/","title":"Current (KVM/Docker)-base LTB Architecture","text":"<p>The following diagram shows the current KVM/Docker based LTB.</p> <p></p> <p>Currently the KVM/Docker based LTB is composed of the following containers:</p> <ul> <li>Frontend built with React</li> <li>Backend built with Django</li> <li>Deployment built with docker-compose</li> </ul>"},{"location":"architecture/kvm-docker-ltb-architecture/#backend","title":"Backend","text":"<p>The backend is accessible via API and a Admin Web UI. It is responsible for the following tasks:</p> <ul> <li>parsing the yaml topology files</li> <li>deploying/destroying the containers and vms</li> <li>exposes status of lab deployments</li> <li>exposes information on how to access the deployed containers and vms</li> <li>provides remote ssh capabilities</li> <li>provides remote Wireshark capture capabilities</li> <li>managing reservations (create, delete, etc.)</li> <li>exposes node resource usage</li> <li>user management</li> <li>exposes information about a device (version, groups, etc.)</li> </ul> <p>It is composed of the following components:</p> <ul> <li>Reservations</li> <li>Running lab store</li> <li>Template store</li> <li>Authentication</li> </ul> <p>The orchestration component is responsible for creating different tasks using Celery and executing them on a remote host. There are 4 different types of tasks:</p> <ul> <li>DeploymentTask</li> <li>Deploys containers in docker</li> <li>Deploys VMs using KVM</li> <li>Creates connections between containers and VMs using an OVS bridge</li> <li>RemovalTask</li> <li>Removes a running lab</li> <li>MirrorInterfaceTask</li> <li>Creates a mirror interface on a connection</li> <li>SnapshotTask</li> <li>Takes a snapshot of a running lab</li> </ul>"},{"location":"architecture/kvm-docker-ltb-architecture/#reservations","title":"Reservations","text":"<p>The reservation component is responsible for reserving system resources in advance. It is responsible for the following tasks:</p> <ul> <li>Create a reservation</li> <li>Delete a reservation</li> <li>Update a reservation</li> </ul>"},{"location":"architecture/kvm-docker-ltb-architecture/#running-lab-store","title":"Running lab store","text":"<p>This component is responsible for storing information about running labs, such as:</p> <ul> <li>The devices taking part in the running lab, inclusive of the interfaces</li> <li>Connection information</li> </ul>"},{"location":"architecture/kvm-docker-ltb-architecture/#template-store","title":"Template store","text":"<p>This component is responsible for storing lab templates.</p>"},{"location":"architecture/kvm-docker-ltb-architecture/#authentication","title":"Authentication","text":"<p>This component is responsible for user authentication and management.</p>"},{"location":"architecture/kvm-docker-ltb-architecture/#deployment","title":"Deployment","text":"<p>The deployment component is responsible for deploying the LTB backend and frontend components.</p>"},{"location":"architecture/kvm-docker-ltb-architecture/#frontend","title":"Frontend","text":"<p>The frontend allows users to access their labs and their devices.</p>"},{"location":"contributor/coding-conventions/","title":"Coding Conventions","text":""},{"location":"contributor/coding-conventions/#naming","title":"Naming","text":"<p>The following naming conventions are used in the project:</p>"},{"location":"contributor/coding-conventions/#naming-conventions-in-go","title":"Naming conventions in Go","text":"<ul> <li>camelCase for variables and functions</li> <li>PascalCase for types and functions that need to be exported</li> </ul>"},{"location":"contributor/coding-conventions/#examples","title":"Examples","text":"<ul> <li>labStatus: variable name for a status of a lab instance</li> <li>GetLabStatus: name for an exported function</li> </ul>"},{"location":"contributor/coding-conventions/#coding","title":"Coding","text":"<ul> <li>The Go extension in VSCode has a linting capability, so that will be used for linting.</li> </ul>"},{"location":"contributor/dev-cluster-setup/","title":"Development cluster setup","text":"<p>Setup for a development Kubernetes cluster.</p>"},{"location":"contributor/dev-cluster-setup/#prerequisites","title":"Prerequisites","text":"<p>WSL version 0.67.6 and higher</p> <p>Active Ubuntu WSL needed:</p> <pre><code>sudo vim /etc/wsl.conf\n</code></pre> <pre><code># /etc/wsl.conf\n[boot]\nsystemd=true\n</code></pre> <p>Restart WSL with <code>wsl.exe --shutdown</code> and opening the WSL again.</p>"},{"location":"contributor/dev-cluster-setup/#option-1-k3s-install","title":"Option 1: K3S install","text":"<pre><code>sudo mkdir -p /etc/rancher/k3s/\nsudo vim /etc/rancher/k3s/config.yaml\n</code></pre> <pre><code># /etc/rancher/k3s/config.yaml\nwrite-kubeconfig-mode: \"0644\"\n</code></pre> <pre><code>curl -sfL https://get.k3s.io | INSTALL_K3S_VERSION=\"v1.26.1+k3s1\" sudo -E sh -\nln -s /etc/rancher/k3s/k3s.yaml ~/.kube/k3s.yaml\necho \"export KUBECONFIG=${KUBECONFIG}:${HOME}/.kube/k3s.yaml\" &gt;&gt; ~/.bashrc\n</code></pre>"},{"location":"contributor/dev-cluster-setup/#option-2-k3d-install","title":"Option 2: K3D install","text":"<p>Prerequisites: Docker Desktop installed and running or Docker installed in WSL</p> <pre><code>curl -s https://raw.githubusercontent.com/k3d-io/k3d/main/install.sh | TAG=v5.4.7 bash\n</code></pre>"},{"location":"contributor/dev-cluster-setup/#option-3-k0s-install","title":"Option 3: K0s install","text":"<pre><code>curl -sSfL https://get.k0s.sh | K0S_VERSION=v1.26.1+k0s.0 sudo -E sh\n</code></pre>"},{"location":"contributor/dev-cluster-setup/#operator-sdk-install","title":"Operator SDK install","text":""},{"location":"contributor/dev-cluster-setup/#prerequisites_1","title":"Prerequisites","text":"<ul> <li>curl</li> <li>gpg\u00a0version 2.0+</li> </ul>"},{"location":"contributor/dev-cluster-setup/#1-download-the-release-binary","title":"1. Download the release binary","text":"<p>Set platform information:</p> <pre><code>export ARCH=$(case $(uname -m) in x86_64) echo -n amd64 ;; aarch64) echo -n arm64 ;; *) echo -n $(uname -m) ;; esac)\nexport OS=$(uname | awk '{print tolower($0)}')\n</code></pre> <p>Download the binary for your platform:</p> <pre><code>export OPERATOR_SDK_Version=1.26.1\nexport OPERATOR_SDK_DL_URL=https://github.com/operator-framework/operator-sdk/releases/download/${OPERATOR_SDK_Version}\ncurl -LO ${OPERATOR_SDK_DL_URL}/operator-sdk_${OS}_${ARCH}\n</code></pre>"},{"location":"contributor/dev-cluster-setup/#2-verify-the-downloaded-binary-optional","title":"2. Verify the downloaded binary (Optional)","text":"<p>Import the operator-sdk release GPG key from\u00a0<code>keyserver.ubuntu.com</code>:</p> <pre><code>gpg --keyserver keyserver.ubuntu.com --recv-keys 052996E2A20B5C7E\n</code></pre> <p>Download the checksums file and its signature, then verify the signature (optional):</p> <pre><code>curl -LO ${OPERATOR_SDK_DL_URL}/checksums.txt\ncurl -LO ${OPERATOR_SDK_DL_URL}/checksums.txt.asc\ngpg -u \"Operator SDK (release) &lt;cncf-operator-sdk@cncf.io&gt;\" --verify checksums.txt.asc\n</code></pre> <p>You should see something similar to the following:</p> <pre><code>gpg: assuming signed data in 'checksums.txt'\ngpg: Signature made Fri 30 Oct 2020 12:15:15 PM PDT\ngpg:                using RSA key ADE83605E945FA5A1BD8639C59E5B47624962185\ngpg: Good signature from \"Operator SDK (release) &lt;cncf-operator-sdk@cncf.io&gt;\" [ultimate]\n</code></pre> <p>Make sure the checksums match:</p> <pre><code>grep operator-sdk_${OS}_${ARCH} checksums.txt | sha256sum -c -\n</code></pre> <p>You should see something similar to the following:</p> <pre><code>operator-sdk_linux_amd64: OK\n</code></pre>"},{"location":"contributor/dev-cluster-setup/#3-install-the-release-binary-in-your-path","title":"3. Install the release binary in your PATH","text":"<pre><code>chmod +x operator-sdk_${OS}_${ARCH} &amp;&amp; sudo mv operator-sdk_${OS}_${ARCH} /usr/local/bin/operator-sdk\n</code></pre> <p>Verify the installation:</p> <pre><code>operator-sdk version\n</code></pre>"},{"location":"contributor/dev-cluster-setup/#install-go","title":"Install Go","text":"<p>Step 1 - Downloading Go lang binary files Visit official downloads page and grab file using either wget command or curl command:</p> <pre><code># let us download a file with curl on Linux command line #\nGO_VERSION=\"1.20.1\" # go version\nARCH=\"amd64\" # go archicture\nwget -L \"https://golang.org/dl/go${GO_VERSION}.linux-${ARCH}.tar.gz\"\nrm -rf /usr/local/go &amp;&amp; tar -C /usr/local -xzf go${GO_VERSION}.linux-${ARCH}.tar.gz\n</code></pre> <p>Step 2  - Add to PATH</p> <pre><code>echo 'export PATH=\"$PATH:/usr/local/go/bin\"' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre> <p>Step 3 - Verify that you've installed Go by opening a command prompt and typing the following command:</p> <pre><code>go version\n</code></pre>"},{"location":"contributor/technologies-used/","title":"Tools and Frameworks","text":"<p>The tools and frameworks used in the project are listed below.</p>"},{"location":"contributor/technologies-used/#go-based-operator-sdk-framework","title":"Go-based Operator SDK framework","text":"<p>To create the LTB operator, we used the Go-based Operator-sdk framework, which helps us to make the LTB application Kubernetes native.</p>"},{"location":"contributor/technologies-used/#kubevirt","title":"Kubevirt","text":"<p>Kubevirt is a tool that provides a virtual machine management layer on top of Kubernetes. It allows us to deploy virtual machines on Kubernetes.</p>"},{"location":"contributor/technologies-used/#kubernetes","title":"Kubernetes","text":"<p>We use Kubernetes as the container orchestration platform for the LTB application.</p>"},{"location":"contributor/test-concepts/","title":"Test Concept","text":""},{"location":"contributor/test-concepts/#overview","title":"Overview","text":"<p>This document outlines the approaches, methodologies, and types of tests that will be used to ensure the LTB K8s Backend components are functioning as expected.</p>"},{"location":"contributor/test-concepts/#test-categories","title":"Test categories","text":"<p>The tests will primarily focus on the following category:</p> <ul> <li>Functionality and Logic: This includes automated integration tests to evaluate how the LTB K8s Backend interacts with other components of the LTB application, such as the operator's function in a Kubernetes cluster with a K8s API server and other resources.</li> </ul> <p>Testing in the other categories, such as Security and Performance, will be considered later time and their specifics will be determined accordingly.</p>"},{"location":"contributor/test-concepts/#tools","title":"Tools","text":"<p>The tools listed below are going to be used to perform the tests mentioned above. Moreover, the tools are used in a suite test, which is created when a controller is scaffolded by the tool.</p> <ul> <li>Testify: a go package that provides a set of features to perform unit tests, such as assertions, mocks, etc.</li> <li>EnvTest: a Go library that helps write integration tests for Kubernetes controllers by setting up an instance of etcd and a Kubernetes API server, without kubelet, controller-manager, or other components.</li> <li>Ginkgo: a Go testing framework for Go to help you write epxressive, readable, and maintainable tests. It is best used with the Gomega matcher library.</li> <li>Gomega: a Go matcher library that provides a set of matchers to perform assertions in tests. It is best used with the Ginkgo testing framework.</li> </ul>"},{"location":"contributor/test-concepts/#strategies-test-approach","title":"Strategies: Test Approach","text":"<p>The following test approaches are going to be used to test the LTB K8s Backend components:</p>"},{"location":"contributor/test-concepts/#unit-tests","title":"Unit Tests","text":"<p>Unit tests are going to be used to test small pieces of code, such as functions, which don't involve setting up testing Kubernetes environment with a K8s API server and other resources.</p>"},{"location":"contributor/test-concepts/#integration-tests","title":"Integration Tests","text":"<p>Integration tests are going to be used to test the different components of the LTB K8s Backend, such as the operator, the controllers, etc., and how they interact with each other.</p>"},{"location":"contributor/test-concepts/#environment","title":"Environment","text":"<p>EnvTest is going to be used to set up a testing Kubernetes environment with a K8s API server and other resources.</p>"},{"location":"decisions/0000-use-markdown-architectural-decision-records/","title":"Use Markdown Architectural Decision Records","text":""},{"location":"decisions/0000-use-markdown-architectural-decision-records/#context-and-problem-statement","title":"Context and Problem Statement","text":"<p>We want to record design decisions made in this project. Which format and structure should these records follow?</p>"},{"location":"decisions/0000-use-markdown-architectural-decision-records/#considered-options","title":"Considered Options","text":"<ul> <li>MADR 2.1.2 \u2013 The Markdown Architectural Decision Records</li> <li>Michael Nygard's template \u2013 The first incarnation of the term \"ADR\"</li> <li>Sustainable Architectural Decisions \u2013 The Y-Statements</li> <li>Other templates listed at https://github.com/joelparkerhenderson/architecture_decision_record</li> <li>Formless \u2013 No conventions for file format and structure</li> </ul>"},{"location":"decisions/0000-use-markdown-architectural-decision-records/#decision-outcome","title":"Decision Outcome","text":"<p>Chosen option: \"MADR 2.1.2\", because</p> <ul> <li>Implicit assumptions should be made explicit.   Design documentation is important to enable people understanding the decisions later on.   See also A rational design process: How and why to fake it.</li> <li>The MADR format is lean and fits our development style.</li> <li>The MADR structure is comprehensible and facilitates usage &amp; maintenance.</li> <li>The MADR project is vivid.</li> <li>Version 2.1.2 is the latest one available when starting to document ADRs.</li> <li>A Visual Studio Code extension ADR Manager for MADR exits, which makes managing ADRs easy.</li> </ul>"},{"location":"decisions/0001-operator-SDK/","title":"Operator SDK","text":""},{"location":"decisions/0001-operator-SDK/#context-and-problem-statement","title":"Context and Problem Statement","text":"<p>It's best practice to use an SDK to build operators for Kubernetes. The SDK provides a higher level of abstraction for creating Kubernetes operators, which makes it easier to write and manage operators. There are multiple SDKs available for building operators. We need a SDK that's flexible and easy to use and can be used with Go.</p>"},{"location":"decisions/0001-operator-SDK/#considered-options","title":"Considered Options","text":"<ul> <li>Operator SDK (Operator Framework)</li> <li>KubeBuilder</li> <li>Kopf</li> <li>KUDO</li> <li>Metacontroller</li> </ul>"},{"location":"decisions/0001-operator-SDK/#decision-outcome","title":"Decision Outcome","text":"<p>Chosen option: \"Operator SDK\", because it provides a high level of abstraction for creating Kubernetes operators, which makes it easier to write and manage operators. Additionally, there are tools and libraries for building and testing the operator included in Operator SDK, it's easy to use and can be used with Go.</p>"},{"location":"decisions/0001-operator-SDK/#more-information","title":"More Information","text":"<ul> <li>Operator SDK</li> <li>Tools to build an operator</li> </ul>"},{"location":"decisions/00011-remote-access/","title":"Remote-Access","text":""},{"location":"decisions/00011-remote-access/#context-and-problem-statement","title":"Context and Problem Statement","text":"<p>For the labinstances to be usefull for the students, they need to be able to access the pods (containers) and VMs. The access should be restricted to the pods/VMs the user is allowed to access. It should be possible to access the pods/VMs console and or access it via multiple OOB protocols (SSH, RDP, VNC, ...).</p>"},{"location":"decisions/00011-remote-access/#considered-options","title":"Considered Options","text":"<ul> <li>Kubernetes Service</li> <li>Gotty</li> <li>ttyd</li> </ul>"},{"location":"decisions/00011-remote-access/#decision-outcome","title":"Decision Outcome","text":"<p>Chosen option: \"ttyd and Kubernetes Service\", ttyd will be used as a jump host to access the pods/VMs console, and a Kubernetes service (LoadBalancer) will be used to access the pods/VMs via OOB protocols. Security for the console access will likely be easy to implement. Secure access via OOB protocols was considered, but will need to be reasearched further.</p>"},{"location":"decisions/0002-operator-scope/","title":"Operator Scope","text":""},{"location":"decisions/0002-operator-scope/#context-and-problem-statement","title":"Context and Problem Statement","text":"<p>The Operator could be a namespace-scoped or cluster-scoped.</p>"},{"location":"decisions/0002-operator-scope/#considered-options","title":"Considered Options","text":"<ul> <li>Namespace-scoped</li> <li>Cluster-scoped</li> </ul>"},{"location":"decisions/0002-operator-scope/#decision-outcome","title":"Decision Outcome","text":"<p>Chosen option: \"Cluster-scoped\", because cluster-scoped operators enables you to manage namespaces or resources in the entire cluster. They are also capable of managing infrastructure-level resources, such as nodes. Additionally, cluster-scoped operators provide us greater visibility and control over the entire cluster.</p>"},{"location":"decisions/0002-operator-scope/#more-information","title":"More Information","text":"<ul> <li>Operator Scope</li> </ul>"},{"location":"decisions/0003-api-and-operator-run-in-one-container/","title":"API and Operator Run in One Container","text":""},{"location":"decisions/0003-api-and-operator-run-in-one-container/#context-and-problem-statement","title":"Context and Problem Statement","text":"<p>The operator and the API could be separated and deployed as two services/containers.</p>"},{"location":"decisions/0003-api-and-operator-run-in-one-container/#considered-options","title":"Considered Options","text":"<ul> <li>One container</li> <li>Separate containers</li> </ul>"},{"location":"decisions/0003-api-and-operator-run-in-one-container/#decision-outcome","title":"Decision Outcome","text":"<p>Chosen option: \"One container\", because it simplifies the deployment and implementation as everything will be written in one programming language, with the drawback that the components can't be exchanged easily.</p>"},{"location":"decisions/0004-dev-container/","title":"DevContainer","text":""},{"location":"decisions/0004-dev-container/#context-and-problem-statement","title":"Context and Problem Statement","text":"<p>Every team member could set up their development environment manually or they can create an automated and same development environment for everyone by using a DevContainer.</p>"},{"location":"decisions/0004-dev-container/#considered-options","title":"Considered Options","text":"<ul> <li>DevContainer</li> <li>Manual Setup</li> </ul>"},{"location":"decisions/0004-dev-container/#decision-outcome","title":"Decision Outcome","text":"<p>Chosen option: \"DevContainer\", because DevContainer setup lets you create the same development environment for all team members, which ensures consistency. It also provides a completely isolated development environment, which helps to avoid software incompatibility issues, such as operator-sdk not working on Windows. Moreover, DevContainer is easily portable and can be shared between team members irrespective of the operating system they use.</p>"},{"location":"decisions/0004-dev-container/#more-information","title":"More Information","text":"<ul> <li>DevContainer</li> </ul>"},{"location":"decisions/0005-replace-current-ltb-backend/","title":"Replace Current LTB Backend","text":""},{"location":"decisions/0005-replace-current-ltb-backend/#context-and-problem-statement","title":"Context and Problem Statement","text":"<p>The LTB K8s Backend could replace the current LTB Backend fully or partially by leaving features, such as User-Management in the current LTB Backend.</p>"},{"location":"decisions/0005-replace-current-ltb-backend/#considered-options","title":"Considered Options","text":"<ul> <li>Replace current LTB Backend fully</li> <li>Replace current LTB Backend partially</li> </ul>"},{"location":"decisions/0005-replace-current-ltb-backend/#decision-outcome","title":"Decision Outcome","text":"<p>Chosen option: \"Replace current LTB Backend fully\", because huge parts of the current LTB Backend would need to be rewritten to be compatible with the new LTB K8s operator.</p>"},{"location":"decisions/0006-lab-instance-set/","title":"Lab Instance Set","text":""},{"location":"decisions/0006-lab-instance-set/#context-and-problem-statement","title":"Context and Problem Statement","text":"<p>We could use one CR, LabInstanceSet, and tell the operator we want e.g. 10 LabInstances  by only providing one LabInstance CR or we could provide the operator 10 CRs to create 10 LabInstances.</p>"},{"location":"decisions/0006-lab-instance-set/#considered-options","title":"Considered Options","text":"<ul> <li>With LabInstanceSet</li> <li>Without LabInstanceSet</li> </ul>"},{"location":"decisions/0006-lab-instance-set/#decision-outcome","title":"Decision Outcome","text":"<p>Chosen option: \"With LabInstanceSet\", because it is easier to manage, and helps to avoid redundancy...</p>"},{"location":"decisions/0007-deployment-to-k8s/","title":"Deployment to K8s","text":""},{"location":"decisions/0007-deployment-to-k8s/#context-and-problem-statement","title":"Context and Problem Statement","text":"<p>Files could be stored in git and deployed to a K8s cluster from there or we could use the frontend for that case.</p>"},{"location":"decisions/0007-deployment-to-k8s/#considered-options","title":"Considered Options","text":"<ul> <li>Store files in Git</li> <li>Use frontend</li> </ul>"},{"location":"decisions/0007-deployment-to-k8s/#decision-outcome","title":"Decision Outcome","text":"<p>Chosen option: \"Store files in Git\", because it makes automation of the deployment easier and reduces the possibility of human errors.</p>"},{"location":"decisions/0008-namespace-per-labinstance/","title":"Namespace Per LabInstance","text":""},{"location":"decisions/0008-namespace-per-labinstance/#context-and-problem-statement","title":"Context and Problem Statement","text":"<p>LabInstance could be created in separate namespaces or one namespace for all LabInstances.</p>"},{"location":"decisions/0008-namespace-per-labinstance/#considered-options","title":"Considered Options","text":"<ul> <li>One Namespace for all LabInstances</li> <li>Namespace per LabInstance</li> </ul>"},{"location":"decisions/0008-namespace-per-labinstance/#decision-outcome","title":"Decision Outcome","text":"<p>Chosen option: \"Namespace per LabInstance\", because not decided yet.</p>"},{"location":"decisions/0009-k8s-aggreted-api-over-standalone-api/","title":"K8s Aggreted API Over Standalone API","text":""},{"location":"decisions/0009-k8s-aggreted-api-over-standalone-api/#context-and-problem-statement","title":"Context and Problem Statement","text":"<p>We want a declarative way of creating LTB labs inside Kubernetes using Kubernetes native pods and KubeVirt virtual machines.</p>"},{"location":"decisions/0009-k8s-aggreted-api-over-standalone-api/#considered-options","title":"Considered Options","text":"<ul> <li>Standalone API</li> <li>Aggregated API</li> </ul>"},{"location":"decisions/0009-k8s-aggreted-api-over-standalone-api/#decision-outcome","title":"Decision Outcome","text":"<p>Chosen option: \"Aggregated API\", because Is better suited for declerative API, our new types will be readable and writeable using kubectl/Kubernetes tools, such as dashboards. We also can leverage Kuberbetes API support features this way. Our resources are scoped to a cluster or namespaces of a cluster.</p>"},{"location":"decisions/0010-extending-ltb-with-new-node-types/","title":"Extending LTB with New Node Types","text":"<ul> <li>Status: Proposed</li> </ul>"},{"location":"decisions/0010-extending-ltb-with-new-node-types/#context-and-problem-statement","title":"Context and Problem Statement","text":"<p>It should be possible to create, update and delete node types (e.g. Ubuntu, XRD, XR, IOS, Cumulus etc.) Node types should be used inside lab templates and expose a way to provide a node with configuration (cloud-init, zero-touch, etc.) The amount of available network interfaces is dynamic and depends on how many connections a node has according to a specific lab template.</p>"},{"location":"decisions/0010-extending-ltb-with-new-node-types/#decision-drivers","title":"Decision Drivers","text":"<ul> <li>Certain operating systems' images like XR, and XRD need a specific interface configuration which depends on how many interfaces a certain node will receive.</li> <li>The chosen solution should support multiple version of a type in an easy to use way (e.g. Ubuntu 22.04, 20.04, ...).</li> <li>For XRd images, interfaces need to have environment variables set for each interface they use, and the interface count needs to be dynamically set according to the lab template.</li> <li>For XR VM images, the first interface is the management interface and then there are two empty interfaces need a special configuration.</li> <li>For mount from config might be different</li> <li>Cumulus VX images need a privileged container</li> <li>XRd need additional privileges</li> </ul>"},{"location":"decisions/0010-extending-ltb-with-new-node-types/#considered-options","title":"Considered Options","text":"<ul> <li>Custom Resources</li> <li>Go</li> </ul>"},{"location":"decisions/0010-extending-ltb-with-new-node-types/#decision-outcome","title":"Decision Outcome","text":"<p>Chosen option: \"Custom Resources\", because it will be possible to support all the cases mentioned in the decision drivers using go templates and a CRs. Implementing the types in Go does not seem to bring any major advantages, whereas using CRs will be easier for external users to extend the system with new node types.</p>"},{"location":"decisions/0010-extending-ltb-with-new-node-types/#positive-consequences","title":"Positive Consequences","text":"<ul> <li>Easy to extend during runtime</li> <li>Easy to extend for external users</li> <li>All decision drivers will be supported</li> </ul>"},{"location":"decisions/0010-extending-ltb-with-new-node-types/#negative-consequences","title":"Negative Consequences","text":"<ul> <li>Go Templates are not as powerful as Go, which could make it harder.</li> </ul>"},{"location":"decisions/0010-extending-ltb-with-new-node-types/#links","title":"Links","text":"<ul> <li>https://github.com/vrnetlab/vrnetlab</li> </ul>"}]}